{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "- Simple linear regression (SLR) is a statistical method that models the relationship between two quantitative variables, an independent variable (predictor) and a dependent variable (outcome), using a straight line. Its purpose is to analyze and quantify the linear relationship between these variables, estimate the strength of the relationship, and make predictions about the dependent variable based on the independent variable.\n",
        "\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "- The key assumptions of Simple Linear Regression (SLR) are as follows:\n",
        "\n",
        "Linearity:\n",
        "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
        "This means changes in X lead to proportional changes in Y.\n",
        "\n",
        "Independence of Errors:\n",
        "The residuals (errors) are independent of each other.\n",
        "There should be no correlation between the errors of one observation and another.\n",
        "\n",
        "Normality of Errors\n",
        "The residuals (errors) should be normally distributed.\n",
        "This is especially important for valid hypothesis testing (e.g., t-tests, F-tests).\n",
        "\n",
        "No Multicollinearity:\n",
        "In simple regression, since there's only one independent variable, this assumption is automatically satisfied.\n",
        "\n",
        "3. Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "-Simple Linear Regression Equation The mathematical equation for a simple linear regression model is\n",
        "\n",
        "y = Bo + B1X + e\n",
        "\n",
        "a. Y - Dependent Variable (Response Variable):\n",
        "The variable we are trying to predict or explain.\n",
        "Example: House price, sales amount, etc.\n",
        "\n",
        "b. X -  Independent Variable (Predictor Variable):\n",
        "The variable used to predict the value of Y.\n",
        "Example: Size of the house, amount of advertising, etc.\n",
        "\n",
        "c. Bo - Intercept (Constant Term):\n",
        "The value of Y when X = 0.\n",
        "It represents the baseline level of Y without influence from X.\n",
        "\n",
        "d. B1 - Slope (Regression coefficent):\n",
        "It shows change in Y for a one - unit change in X.\n",
        "If B1 > 0 : Y increases as X increases.\n",
        "If B1 < 0 : Y decreases as X increases.\n",
        "\n",
        "e. e - Error term (Residual):\n",
        "Represents random variation or factors affecting Y that are not explained by X.\n",
        "It accounts for the difference between the observed and predicted values of Y.\n",
        "\n",
        "4.  Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "- Predicting House Prices Based on Size\n",
        "\n",
        "Scenario:\n",
        "A real estate company wants to predict the price of a house (Y) based on its size in square feet (X).\n",
        "\n",
        "Dependent Variable (Y): House price (in ₹ or $)\n",
        "\n",
        "Independent Variable (X): Size of the house (in square feet)\n",
        "\n",
        "Using past data (historical sales records), the company fits a simple linear regression model:\n",
        "\n",
        "Price=β0+β1xSize+ε\n",
        "\n",
        "Suppose the model gives:\n",
        "\n",
        "Price=50,000+3,000xSize\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "Intercept (β₀ = 50,000):\n",
        "When the house size is 0 sq.ft (theoretically), the base value of a property is ₹50,000.\n",
        "(This may represent fixed costs like land, permits, etc.)\n",
        "\n",
        "Slope (β₁ = 3,000):\n",
        "For every additional square foot, the house price increases by ₹3,000.\n",
        "\n",
        "Prediction Example:\n",
        "If a house is 1,200 sq.ft, then:\n",
        "Predicted Price=50,000+3,000(1,200)=3,650,000\n",
        "So, the model predicts a ₹36.5 lakh price for a 1,200 sq.ft house.\n",
        "\n",
        "5. What is the method of least squares in linear regression?\n",
        "\n",
        "- The method of least squares is the most commonly used technique to find the best-fitting line in a linear regression model.\n",
        "It determines the line that minimizes the sum of the squared differences between the observed values and the predicted values.\n",
        "\n",
        "a. The Linear Regression Model:\n",
        "   Y=β0+β1X+ε\n",
        "   \n",
        "   Where:\n",
        "   Y : Dependent Variable (actual value)\n",
        "   X : Independent variable (predictor)\n",
        "   B0 : Intercept\n",
        "   B1 : Slope\n",
        "   e : Error term ( difference between observed and predicted value)\n",
        "\n",
        "   Objective of the Least Squares Method:\n",
        "\n",
        "   Minimize error: The primary goal is to find a model (line, curve, or plane) that minimizes the sum of the squared differences between the observed data points and the values predicted by the model.\n",
        "   Find the best-fit curve: It is used to find a single, optimal curve that represents a dataset, which is especially useful when no single equation can perfectly pass through all points.\n",
        "   Determine relationships: It helps in estimating the relationship between two or more variables by providing a quantitative model to describe their trend.   \n",
        "\n",
        "   Solving for the Coefficients\n",
        "   By minimizing SSE with respect to B0 and B1\n",
        "\n",
        "   Interpretation\n",
        "\n",
        "   The least squares line (also called the regression line) is the line that best fits the data by minimizing the total squared distance between observed and predicted values.\n",
        "\n",
        "   Example\n",
        "\n",
        "   If we are predicting sales (Y) from advertising spend (X):\n",
        "   The least squares method finds the best line such that the sum of squared differences between the actual and predicted sales is as small as possible.\n",
        "   This ensures the smallest possible overall prediction error.\n",
        "\n",
        "\n",
        "6. What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "- Logistic regression predicts a categorical outcome, like a yes/no answer, by modeling the probability of an event using an S-shaped curve, while linear regression predicts a continuous outcome, like a house price or temperature, using a straight line to show a linear relationship between variables. The main differences lie in their application (classification vs. regression), output (probability vs. continuous value), and the underlying mathematical function used.  \n",
        "\n",
        "Logistic Regression\n",
        "Purpose: Primarily used for classification problems.\n",
        "Output: Predicts the probability of a categorical outcome (e.g., 0 or 1, yes or no).\n",
        "Model: Uses a logistic or sigmoid function, which results in an S-shaped curve and constrains the output to a range between 0 and 1.\n",
        "Example: Predicting whether an email is spam or not spam, or whether a patient has a disease or not.\n",
        "\n",
        "\n",
        "Linear Regression\n",
        "Purpose: Primarily used for regression problems.\n",
        "Output: Predicts a continuous numerical value (e.g., any number from negative infinity to positive infinity).\n",
        "Model: Uses a linear equation, which results in a straight line.\n",
        "Example: Predicting the price of a house based on its features or the temperature on a given day.  \n",
        "\n",
        "7. Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "- Here are three common evaluation metrics used to assess the performance of regression models:\n",
        "\n",
        "a. Mean Absolute Error (MAE):\n",
        "MAE measures the average absolute difference between the actual values and the predicted values.\n",
        "\n",
        "It tells us how far, on average, the predictions are from the true values, regardless of direction.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "Lower MAE → Better model accuracy.\n",
        "Easy to interpret because it is in the same units as the target variable.\n",
        "\n",
        "b. Mean Squared Error (MSE)\n",
        "Description:\n",
        "MSE measures the average of the squared differences between actual and predicted values.\n",
        "It penalizes large errors more heavily because of the squaring.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "Lower MSE → Better fit.\n",
        "\n",
        "Sensitive to outliers (a single large error can increase MSE significantly).\n",
        "\n",
        "c. R-squared (Coefficient of Determination)\n",
        "\n",
        "Description:\n",
        "R² represents the proportion of variance in the dependent variable (Y) that is explained by the independent variable(s) in the model.\n",
        "\n",
        "Interpretation:\n",
        "R² ranges from 0 to 1.\n",
        "R² = 1: Perfect prediction\n",
        "R² = 0: Model does not explain any variability in Y\n",
        "Higher R² indicates a better fit of the model.\n",
        "\n",
        "8. What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "- The purpose of the R-squared (R²) metric is to measure the goodness of fit in a regression model by indicating the proportion of variance in the dependent variable that is explained by the independent variables. It quantifies how well the model's predictions fit the actual data, with a higher R-squared value (between 0 and 1) meaning the model explains a greater percentage of the variance, and a lower value indicating a poorer fit.\n",
        "\n",
        "Key functions of R-squared\n",
        "\n",
        " Quantifies model fit: R-squared provides a single, easy-to-understand value that represents the percentage of variation in the dependent variable that is predictable from the independent variables.\n",
        "\n",
        " Assesses explanatory power: A high R-squared value indicates that the independent variables are good predictors of the dependent variable, while a low value means they are not. For example, an R-squared of 0.76 means that 76% of the variation in the dependent variable is explained by the model, and 24% is due to other, unmeasured factors.\n",
        "\n",
        " Allows for comparison of models: R-squared is useful for comparing the performance of different models on the same data, as a model with a higher R-squared value generally provides a better fit.\n",
        "\n",
        " Measures variability: It helps determine how much the data points scatter around the fitted regression line. A value of 1 indicates a perfect fit, while a value of 0 indicates that the model does not explain any of the variability beyond the mean.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jqkHWlOfF8mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.(Include your Python code and output in the code box below.)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "print(\"Slope (β1):\", model.coef_[0])\n",
        "print(\"Intercept (β0):\", model.intercept_)\n",
        "\n",
        "Y_pred = model.predict(X)\n",
        "print(\"Predicted Values:\", Y_pred)\n"
      ],
      "metadata": {
        "id": "AC44iuWYGCj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a677e64-b948-4161-edb8-6929e581d8fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (β1): 0.6\n",
            "Intercept (β0): 2.2\n",
            "Predicted Values: [2.8 3.4 4.  4.6 5.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do you interpret the coefficients in a simple linear regression model?\n",
        "-   Interpreting the Coefficients in a Simple Linear Regression Model\n",
        "    The simple linear regression model is written as:\n",
        "    \n",
        "    Y = B0+B1X+e\n",
        "    \n",
        "    Where:\n",
        "    Y : Dependent (response) variable\n",
        "    X : Independent (predictor) variable\n",
        "    B0: Intercept\n",
        "    B1: Slope (coefficient of X)\n",
        "    e : Error term\n",
        "\n",
        "    a. Intercept(B0)\n",
        "    The intercept represents the predicted value of Y when x = 0\n",
        "    It’s the point where the regression line crosses the Y-axis.\n",
        "\n",
        "    Example:\n",
        "    If the regression equation is\n",
        "\n",
        "    Salary=30,000+2,000×(Years of Experience)\n",
        "    Then:  B0 = 30,000 means that when Years of Experience = 0, the predicted salary = ₹30,000.\n",
        "    It shows the baseline level of Y.\n",
        "     \n",
        "    b. Slope (B1)\n",
        "    The slope represents the change in Y for a one-unit increase in X, keeping other factors constant.\n",
        "\n",
        "    It shows the strength and direction of the relationship:\n",
        "    Positive : Y increases as X increases\n",
        "    Negative : Y decreases as X increases\n",
        "\n",
        "    Example (continued):\n",
        "    B1 = 2,000 means that for each additional year of experience, the salary increases by ₹2,000 (on average).\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "qvVnFy2A6VwV"
      }
    }
  ]
}